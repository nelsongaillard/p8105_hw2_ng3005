---
title: "p8105_hw2_ng3005"
author: "Nelson Gaillard"
date: "2025-09-28"
output: github_document
---

```{r}
library(tidyverse)
library(readxl)
```

### Problem 1

First, let's clean the data in pols-month.csv

```{r}
pols_df =
  read_csv("data/pols-month.csv", na = c("NA", ".", "")) |>
  janitor::clean_names() |>
  separate(
    mon, into = c("year", "month", "day")
  ) |>
  mutate(month = case_match(
    month,
    "01" ~ "January", 
    "02" ~ "February",
    "03" ~ "March",
    "04" ~ "April", 
    "05" ~ "May",
    "06" ~ "June",
    "07" ~ "July", 
    "08" ~ "August",
    "09" ~ "September",
    "10" ~ "October",
    "11" ~ "November",
    "12" ~ "December"
  )) |>
  mutate(year = as.integer(year)) |>
  mutate(president = case_when(
    prez_gop == 1 ~ "gop",
    prez_dem == 1 ~ "dem"
  )) |>
  select(-c(prez_gop, prez_dem, day))
```

Next, let's clean the data in snp.csv

```{r}
snp_df =
  read_csv("data/snp.csv", na = c("NA", ".", "")) |>
  janitor::clean_names() |>
  separate(
    date, into = c("month", "day", "year")
  ) |>
  mutate(month = case_match(
    month,
    "1" ~ "January", 
    "2" ~ "February",
    "3" ~ "March",
    "4" ~ "April", 
    "5" ~ "May",
    "6" ~ "June",
    "7" ~ "July", 
    "8" ~ "August",
    "9" ~ "September",
    "10" ~ "October",
    "11" ~ "November",
    "12" ~ "December"
  )) |>
  mutate(year = as.integer(year)) |>
  mutate(year = ifelse(year > 50, 1900 + year, 2000 + year)) |>
  select(-day) |>
  relocate(year, month, close)
```

Third, let's clean the unemployment.csv data

```{r}
unemployment_df =
  read_csv("data/unemployment.csv", na = c("NA", ".", "")) |>
  janitor::clean_names() |>
  pivot_longer(
    cols = jan:dec,
    names_to = "month",
    values_to = "unemployment_pct"
  ) |>
  mutate(
    year = as.integer(year),
    month = factor(month,
                   levels = tolower(month.abb),
                   labels = month.name),
    month = as.character(month)
  )
```

Finally, we can merge these datasets into one!

```{r}
pols_snp_df =
  left_join(pols_df, snp_df, by = c("year", "month"))

fivethirtyeight_df =
  left_join(pols_snp_df, unemployment_df, by = c("year", "month"))
```

This new dataset `fivethirtyeight_df` contains `r ncol(fivethirtyeight_df)` total columns and `r nrow(fivethirtyeight_df)` rows. The `year` variable ranges from `r min(fivethirtyeight_df$year)` to `r max(fivethirtyeight_df$year)`. Alongside the `year` and `month` data, the dataset breaks down the number of governors, senators, and house representatives in the GOP and Democratic Party using the variables: `gov_gop`, `sen_gop`, `rep_gop`, `gov_dem`, `sen_dem`, and `rep_dem`. Lastly, the newly created `president` variable indicates the political party the active president is from, and `close` refers to the closing values of the S&P stock index on that day the observation was created.



### Problem 2

Let's load in the Mr. Trash Wheel excel sheet and clean

```{r}
trash_df =
  read_excel("data/202509 Trash Wheel Collection Data.xlsx", 
             sheet = "Mr. Trash Wheel",
             range = "A2:N709") |>
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |>
  mutate(sports_balls = as.integer(round(sports_balls)),
         year = as.integer(year),
         wheel = "Mr_Trash", 
         id = paste0(wheel, "_", dumpster))
```

Now, we can load the Professor Trash Wheel excel sheet and clean

```{r}
prof_df = 
  read_excel("data/202509 Trash Wheel Collection Data.xlsx",
             sheet = "Professor Trash Wheel",
             range = "A2:M134") |>
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |>
  mutate(year = as.integer(year),
         wheel = "Professor_Trash",
         id = paste0(wheel, "_", dumpster))
```

Finally, we can load the Gwynnda Trash Wheel excel sheet and clean

```{r}
gwynns_df =
  read_excel("data/202509 Trash Wheel Collection Data.xlsx",
             sheet = "Gwynns Falls Trash Wheel",
             range = "A2:L351") |>
  janitor::clean_names() |>
  filter(!is.na(dumpster)) |>
  mutate(year = as.integer(year),
         wheel = "Gwynns_Falls_Trash",
         id = paste0(wheel, "_", dumpster))
```

Let's join the datasets together

```{r}
trash_prof_gwynns_df =
  bind_rows(trash_df, prof_df, gwynns_df) |>
  select(id, wheel, dumpster, month, year, date, everything())
```

In the new dataset `trash_prof_gwynns_df`, there are `r nrow(trash_prof_gwynns_df)` observations. Some key variables include a new variable, `id`, which identifies the `name` of the trash wheel and the respective `dumpster` number. The remaining variables describe the type and amount of trash each wheel picked up. For example, `cigarette_butts` and `plastic_bottles` and `weight_tons` and `volume_cubic_yards`.

For the available data, the total weight of trash collected by Professor Trash Wheel is `r sum(trash_prof_gwynns_df$weight_tons[trash_prof_gwynns_df$wheel == "Professor_Trash"], na.rm=TRUE)` tons.

For the available data, the Gwynn Falls Trash Wheel picked up a total of `r format(sum(trash_prof_gwynns_df$cigarette_butts[trash_prof_gwynns_df$wheel == "Gwynns_Falls_Trash" & trash_prof_gwynns_df$year == 2022 & trash_prof_gwynns_df$month == "June"], na.rm=TRUE), scientific = FALSE)` cigarette butts in June of 2022.



## Problem 3

Load new datasets to examine

```{r}
zip_df =
  read_csv("data/Zip Codes.csv", na = c("NA", ".", "")) |>
  janitor::clean_names()

zori_df =
  read_csv("data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv", na = c("NA", ".", "")) |>
  janitor::clean_names()
```

Tidy `zori_df`

```{r}
zori_df =
  read_csv("data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv", na = c("NA", ".", "")) |>
  janitor::clean_names() |>
  pivot_longer(
    cols = x2015_01_31:x2024_08_31,
    names_to = "date",
    values_to = "zori") |>
  mutate(county_name = recode(county_name,
                    "Queens County" = "Queens", 
                    "Kings County" = "Kings",
                    "New York County" = "New York",
                    "Bronx County" = "Bronx",
                    "Richmond County" = "Richmond")) |>
  rename(zip_code = region_name,
         county = county_name) |>
  relocate(zip_code, county)

zip_df =
  read_csv("data/Zip Codes.csv", na = c("NA", ".", "")) |>
  janitor::clean_names() |>
  relocate(zip_code, county)
```

Now, in both datasets, we have a column called `zip_code` through which we can merge

```{r}
zip_zori_df =
  left_join(zori_df, zip_df, by = c("zip_code", "county")) |>
  janitor::clean_names() |>
  relocate(county, zip_code, neighborhood, zori)
```

In the tidy dataset `zip_zori_df`, there are a total of `r nrow(zip_zori_df)` observations. There are `r n_distinct(na.omit(zip_zori_df$zip_code))` unique zip codes and `r n_distinct(na.omit(zip_zori_df$neighborhood))` unique neighborhoods.

There are `r n_distinct(zip_df$zip_code) - n_distinct(zori_df$zip_code)` zip codes that appear in `zip_df` that do not appear in `zori_df`. A few examples of zip codes missing from `zori_df` are `r paste(head(setdiff(zip_df$zip_code, zori_df$zip_code), 5))`. These zip codes may be missing from `zori_df` because this dataset includes data from Zillow with the zip codes of neighborhoods with containing rental properties. It is entirely possible that the zip codes included in `zip_df` but not `zori_df` do not contain rental properties (i.e. perhaps these zip codes only consist of properties you can purchase). Similarly, these zip codes may encapsulate neighborhoods in which no people live. 

```{r}
january_df =
  zip_zori_df |>
  mutate(
    date = str_remove(date, "^x"),
    date = str_replace_all(date, "_", "-"),
    date = ymd(date),
    ym =substr(date, 1, 7)) |>
  filter(ym %in% c("2020-01", "2021-01")) |>
  relocate(date)
  
top10_df =
  january_df |>
  mutate(year = substr(ym, 1, 4)) |>
  select(zip_code, county, neighborhood, year, zori) |>
  distinct() |>
  pivot_wider(
    names_from = year,
    values_from = zori,
    names_prefix = "rent_") |>
  mutate(drop = rent_2021 - rent_2020) |>
  select(zip_code, county, neighborhood, rent_2020, rent_2021, drop) |>
  arrange(drop) |>
  head(10)

knitr::kable(top10_df)
```

From the newly generated table, the neighborhood with the greatest rent drop between January 2020 and January 2021 was `r top10_df$neighborhood[1]` with a rent drop of over $`r abs(ceiling(top10_df$drop[1]))`. 


